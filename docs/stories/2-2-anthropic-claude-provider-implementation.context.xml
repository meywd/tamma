<story-context id="bmad/bmm/workflows/4-implementation/story-context" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>2</storyId>
    <title>Anthropic Claude Provider Implementation</title>
    <status>drafted</status>
    <generatedAt>2025-11-08T12:00:00.000Z</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>/home/meywd/tamma/test-platform/docs/stories/2-2-anthropic-claude-provider-implementation.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>developer</asA>
    <iWant>integrate Anthropic Claude AI models into the benchmarking platform</iWant>
    <soThat>I can run benchmarks using Claude's advanced reasoning capabilities for code generation and analysis tasks</soThat>
    <tasks>
- Task 1: Anthropic Provider Setup (AC: #1, #2)
  - Subtask 1.1: Create AnthropicClaudeProvider class implementing IAIProvider
  - Subtask 1.2: Configure Anthropic SDK with proper authentication
  - Subtask 1.3: Implement model discovery for Claude models
  - Subtask 1.4: Add model-specific configuration (context windows, pricing)
- Task 2: Streaming Implementation (AC: #3)
  - Subtask 2.1: Implement streaming response handling
  - Subtask 2.2: Create AsyncIterable&lt;MessageChunk&gt; pattern
  - Subtask 2.3: Handle partial responses and chunk aggregation
  - Subtask 2.4: Add stream cancellation and timeout handling
- Task 3: Error Handling &amp; Resilience (AC: #4, #7)
  - Subtask 3.1: Implement exponential backoff retry logic
  - Subtask 3.2: Add circuit breaker pattern for API failures
  - Subtask 3.3: Handle rate limiting and quota exceeded errors
  - Subtask 3.4: Create custom error types for Anthropic-specific errors
- Task 4: Token &amp; Cost Management (AC: #5)
  - Subtask 4.1: Implement accurate token counting for input/output
  - Subtask 4.2: Add cost calculation based on Claude pricing
  - Subtask 4.3: Create usage tracking and quota management
  - Subtask 4.4: Add cost optimization recommendations
- Task 5: Advanced Features (AC: #6)
  - Subtask 5.1: Implement function calling support
  - Subtask 5.2: Add tool use capabilities for code analysis
  - Subtask 5.3: Create tool definition and validation system
  - Subtask 5.4: Handle tool execution results and errors
- Task 6: Monitoring &amp; Logging (AC: #8)
  - Subtask 6.1: Add structured logging for all API calls
  - Subtask 6.2: Implement metrics collection (latency, success rate)
  - Subtask 6.3: Create performance monitoring dashboards
  - Subtask 6.4: Add alerting for performance degradation</tasks>
  </story>

  <acceptanceCriteria>1. Implement IAIProvider interface for Anthropic Claude API
2. Support Claude 3.5 Sonnet, Claude 3.5 Haiku, and Claude 3 Opus models
3. Handle streaming responses using AsyncIterable pattern
4. Implement proper error handling and retry logic with exponential backoff
5. Include token counting, cost calculation, and rate limiting
6. Support function calling and tool use capabilities
7. Implement circuit breaker pattern for API resilience
8. Add comprehensive logging and metrics collection</acceptanceCriteria>

  <artifacts>
    <docs>
      <artifact path="docs/tech-spec-epic-2.md" title="Epic 2 Technical Specification" section="Anthropic Claude API Provider (Story 1-2)" snippet="Implementation class: AnthropicClaudeProvider implements IAIProvider - Uses Anthropic Claude API via @anthropic-ai/sdk for programmatic/headless access (NOT Claude Code IDE tool) - Streaming response handler with Server-Sent Events (SSE) chunk parsing - Context management with conversation history - Error handling for rate limits (429), network failures, token limits (400) - Retry logic with exponential backoff for transient failures - Telemetry hooks for latency, token usage, error rates" />
      <artifact path="docs/architecture.md" title="System Architecture" section="Technology Stack" snippet="Language: TypeScript 5.7+ (strict mode) - Runtime: Node.js 22 LTS - Package Manager: pnpm 9+ (monorepo with workspaces) - Testing: Vitest 3.x (10-20x faster than Jest) - Logging: Pino (5x faster than Winston)" />
      <artifact path="docs/PRD.md" title="Product Requirements Document" section="AI Provider Integration" snippet="FR-7: System shall provide abstract interface supporting 8+ AI providers (Anthropic Claude, OpenAI, GitHub Copilot, Google Gemini, OpenCode, z.ai, Zen MCP, OpenRouter, local LLMs) with seamless provider switching - FR-8: System shall maintain provider feature matrix documentation for capability comparison and intelligent provider selection based on workflow step (issue analysis vs code generation vs testing vs review) - FR-9: System shall route tasks to optimal AI provider based on cost optimization (target 20-30% cost reduction via subscription plans vs pay-as-you-go) and capability matching per workflow step" />
    </docs>
    <code>
      <artifact path="packages/providers/src/types.ts" kind="interface" symbol="IAIProvider" lines="216-257" reason="Core interface that Anthropic provider must implement - defines contract for all AI providers including initialize, sendMessage, sendMessageSync, getCapabilities, getModels, and dispose methods" />
      <artifact path="packages/providers/src/types.ts" kind="interface" symbol="MessageRequest" lines="131-149" reason="Defines the structure for message requests sent to AI providers including messages array, model parameters, streaming options, and tool definitions" />
      <artifact path="packages/providers/src/types.ts" kind="interface" symbol="MessageChunk" lines="177-196" reason="Defines streaming response chunk structure with content, delta, usage tracking, and metadata for real-time response handling" />
      <artifact path="packages/providers/src/types.ts" kind="interface" symbol="ProviderCapabilities" lines="90-103" reason="Defines provider capabilities including streaming support, tool support, token limits, and available models" />
      <artifact path="packages/providers/src/types.ts" kind="interface" symbol="ProviderError" lines="201-207" reason="Defines error structure with error codes, retryability flags, and severity levels for consistent error handling" />
      <artifact path="packages/providers/src/types.ts" kind="constant" symbol="PROVIDER_TYPES" lines="335-345" reason="Defines provider type constants including ANTHROPIC_CLAUDE for provider registration and discovery" />
      <artifact path="packages/providers/src/types.ts" kind="constant" symbol="PROVIDER_ERROR_CODES" lines="319-330" reason="Defines standardized error codes for rate limiting, authentication failures, and other provider-specific errors" />
      <artifact path="packages/providers/src/types.test.ts" kind="test" symbol="AI Provider Interfaces" lines="20-58" reason="Test patterns for validating IAIProvider interface implementation and contract compliance" />
      <artifact path="packages/providers/package.json" kind="package" symbol="dependencies" lines="19-27" reason="Shows @anthropic-ai/sdk is already available as dependency for implementing the provider" />
    </code>
    <dependencies>
      <ecosystem name="nodejs">
        <package name="@anthropic-ai/sdk" version="^0.68.0" />
        <package name="@tamma/shared" version="workspace:*" />
        <package name="@tamma/observability" version="workspace:*" />
        <package name="typescript" version="~5.7.2" />
        <package name="vitest" version="3.x" />
      </ecosystem>
    </dependencies>
  </artifacts>

  <constraints>
- Interface Implementation: Must implement IAIProvider from packages/providers/src/types.ts
- Streaming Pattern: Use AsyncIterable&lt;MessageChunk&gt; for real-time responses
- Error Handling: Follow ProviderError pattern with structured context and retryable flags
- Circuit Breaker: 5 failures in 60s → open for 300s (per architecture requirements)
- Async/Await: Always use async/await, never .then()/.catch()
- TypeScript Strict: All code must compile with strict mode enabled
- Token Counting: Must track input/output tokens for cost calculation
- Rate Limiting: Handle 429 errors with exponential backoff
- Tool Support: Implement function calling and tool use capabilities
- Logging: Use structured logging with Pino for observability
- Testing: Follow TDD pattern with Vitest, include unit and integration tests
- Configuration: Support environment variables and JSON config files
- Security: Never log API keys, use secure credential management
</constraints>

  <interfaces>
    <interface name="IAIProvider" kind="TypeScript interface" signature="interface IAIProvider { initialize(config: ProviderConfig): Promise&lt;void&gt;; sendMessage(request: MessageRequest, options?: StreamOptions): Promise&lt;AsyncIterable&lt;MessageChunk&gt;&gt;; sendMessageSync(request: MessageRequest): Promise&lt;MessageResponse&gt;; getCapabilities(): ProviderCapabilities; getModels(): Promise&lt;ModelInfo[]&gt;; dispose(): Promise&lt;void&gt;; }" path="packages/providers/src/types.ts" />
    <interface name="MessageRequest" kind="TypeScript interface" signature="interface MessageRequest { messages: Message[]; model?: string; maxTokens?: number; temperature?: number; topP?: number; stream?: boolean; tools?: Array&lt;{ name: string; description: string; input_schema: Record&lt;string, unknown&gt;; }&gt;; metadata?: { traceId?: string; userId?: string; issueId?: string; [key: string]: unknown; }; }" path="packages/providers/src/types.ts" />
    <interface name="ProviderCapabilities" kind="TypeScript interface" signature="interface ProviderCapabilities { supportsStreaming: boolean; supportsImages: boolean; supportsTools: boolean; maxInputTokens: number; maxOutputTokens: number; supportedModels: ModelInfo[]; features: { parallelToolUse?: boolean; promptCaching?: boolean; thinkingMode?: boolean; [key: string]: boolean | undefined; }; }" path="packages/providers/src/types.ts" />
    <interface name="StreamOptions" kind="TypeScript interface" signature="interface StreamOptions { onChunk: (chunk: MessageChunk) =&gt; Promise&lt;void&gt; | void; onError: (error: ProviderError) =&gt; Promise&lt;void&gt; | void; onComplete: () =&gt; Promise&lt;void&gt; | void; timeout?: number; }" path="packages/providers/src/types.ts" />
  </interfaces>

  <tests>
    <standards>Unit tests with Vitest framework following TDD pattern (Red → Green → Refactor). Test coverage targets: 80% line coverage for core logic, 100% for critical paths (error handling, retry logic, streaming). Mock Anthropic API responses using nock for HTTP mocking. Integration tests with real Anthropic API (test credentials required). Error handling tests for all failure scenarios. Performance tests for streaming and latency. Circuit breaker validation tests.</standards>
    <locations>packages/providers/src/anthropic/ - Provider implementation files, packages/providers/src/anthropic/tests/ - Test files colocated with source, packages/providers/src/anthropic/models/ - Claude model definitions, packages/providers/src/anthropic/types/ - TypeScript interfaces</locations>
    <ideas>
      <test idea="AC-1: Interface Implementation" mappedTo="1">Test that AnthropicClaudeProvider implements all IAIProvider methods correctly and can be registered in provider factory</test>
      <test idea="AC-2: Model Support" mappedTo="2">Test model discovery returns Claude 3.5 Sonnet, Claude 3.5 Haiku, and Claude 3 Opus with correct capabilities and pricing</test>
      <test idea="AC-3: Streaming Responses" mappedTo="3">Test streaming responses produce AsyncIterable&lt;MessageChunk&gt; with proper chunk aggregation and content accumulation</test>
      <test idea="AC-4: Error Handling" mappedTo="4">Test exponential backoff retry logic for transient failures and proper error categorization (retryable vs non-retryable)</test>
      <test idea="AC-5: Token Management" mappedTo="5">Test accurate token counting for input/output messages and cost calculation based on Claude pricing model</test>
      <test idea="AC-6: Function Calling" mappedTo="6">Test function calling support with tool definitions, execution, and result handling</test>
      <test idea="AC-7: Circuit Breaker" mappedTo="7">Test circuit breaker triggers after 5 failures in 60s and opens for 300s with proper recovery</test>
      <test idea="AC-8: Logging &amp; Metrics" mappedTo="8">Test structured logging for all API calls and metrics collection for latency, success rate, and token usage</test>
    </ideas>
  </tests>
</story-context>