# Story 5.1: Structured Logging Implementation

**Epic**: Epic 5 - Observability & Production Readiness  
**Category**: Logging & Observability  
**Priority**: MVP Critical  
**Status**: Draft

## Acceptance Criteria

- [ ] All log statements use structured logging library (Pino recommended)
- [ ] Log format: `{"timestamp": ISO8601, "level": "info/warn/error", "message": "...", "context": {...}}`
- [ ] Context includes: correlation ID, issue number, PR number, actor ID
- [ ] Log levels properly assigned: DEBUG (verbose details), INFO (key milestones), WARN (recoverable issues), ERROR (failures)
- [ ] Logs written to: stdout (for container environments), file (for local development), log aggregation service (optional)
- [ ] Log volume under control: <10 log statements per event for typical flow
- [ ] Sensitive data (API keys, tokens) redacted from all logs
- [ ] Performance impact: <5ms overhead per log statement
- [ ] Log rotation and retention policies implemented
- [ ] Structured search and filtering capabilities

## Technical Context

### Logging Architecture

Based on Epic 5.1 requirements and existing architecture patterns:

```typescript
// Structured Logging Interface
interface StructuredLogger {
  debug(message: string, context?: LogContext): void;
  info(message: string, context?: LogContext): void;
  warn(message: string, context?: LogContext): void;
  error(message: string, error?: Error, context?: LogContext): void;

  // Child logger with inherited context
  child(context: LogContext): StructuredLogger;
}

interface LogContext {
  correlationId?: string;
  issueId?: string;
  prId?: string;
  userId?: string;
  provider?: string;
  platform?: string;
  workflowId?: string;
  stepId?: string;
  duration?: number;
  [key: string]: unknown;
}

interface LogEntry {
  timestamp: string; // ISO 8601 with millisecond precision
  level: 'debug' | 'info' | 'warn' | 'error';
  message: string;
  context: LogContext;
  service: string; // 'orchestrator', 'worker', 'api', etc.
  version: string; // Application version
  hostname?: string; // Host identifier
  pid?: number; // Process ID
}
```

### Pino Configuration

```typescript
// packages/observability/src/logger.ts
import pino, { Logger } from 'pino';
import type { LogContext, StructuredLogger } from './types';

export class TammaLogger implements StructuredLogger {
  private logger: Logger;
  private serviceName: string;

  constructor(serviceName: string, options?: pino.LoggerOptions) {
    this.serviceName = serviceName;

    this.logger = pino({
      name: serviceName,
      level: process.env.LOG_LEVEL || 'info',
      formatters: {
        level: (label) => ({ level: label }),
        log: (object) => {
          // Redact sensitive data
          return this.redactSensitiveData(object);
        },
      },
      timestamp: pino.stdTimeFunctions.isoTime,
      base: {
        service: serviceName,
        version: process.env.APP_VERSION || 'unknown',
        hostname: require('os').hostname(),
        pid: process.pid,
      },
      ...options,
    });
  }

  debug(message: string, context?: LogContext): void {
    this.logger.debug(context, message);
  }

  info(message: string, context?: LogContext): void {
    this.logger.info(context, message);
  }

  warn(message: string, context?: LogContext): void {
    this.logger.warn(context, message);
  }

  error(message: string, error?: Error, context?: LogContext): void {
    const errorContext = {
      ...context,
      error: error
        ? {
            name: error.name,
            message: error.message,
            stack: error.stack,
          }
        : undefined,
    };

    this.logger.error(errorContext, message);
  }

  child(context: LogContext): StructuredLogger {
    return new TammaLogger(this.serviceName, {
      ...this.logger.options,
      base: {
        ...this.logger.options.base,
        ...context,
      },
    });
  }

  private redactSensitiveData(logObject: any): any {
    const sensitiveKeys = [
      'password',
      'token',
      'key',
      'secret',
      'auth',
      'apikey',
      'api_key',
      'authorization',
      'bearer',
    ];

    const redacted = { ...logObject };

    const redactValue = (obj: any, path: string[] = []): any => {
      if (typeof obj !== 'object' || obj === null) {
        return obj;
      }

      if (Array.isArray(obj)) {
        return obj.map((item) => redactValue(item, path));
      }

      const result: any = {};
      for (const [key, value] of Object.entries(obj)) {
        const currentPath = [...path, key];
        const keyLower = key.toLowerCase();

        if (sensitiveKeys.some((sensitive) => keyLower.includes(sensitive))) {
          result[key] = '[REDACTED]';
        } else if (typeof value === 'object' && value !== null) {
          result[key] = redactValue(value, currentPath);
        } else {
          result[key] = value;
        }
      }

      return result;
    };

    return redactValue(redacted);
  }
}
```

### Correlation ID Management

```typescript
// packages/observability/src/correlation.ts
import { randomUUID } from 'crypto';
import { AsyncLocalStorage } from 'async_hooks';

interface CorrelationContext {
  correlationId: string;
  userId?: string;
  issueId?: string;
  prId?: string;
}

class CorrelationManager {
  private storage = new AsyncLocalStorage<CorrelationContext>();

  createCorrelationId(): string {
    return randomUUID();
  }

  runWithContext<T>(context: CorrelationContext, fn: () => T): T {
    return this.storage.run(context, fn);
  }

  getContext(): CorrelationContext | undefined {
    return this.storage.getStore();
  }

  getCorrelationId(): string | undefined {
    return this.getContext()?.correlationId;
  }

  withCorrelation<T>(correlationId: string, fn: () => T): T {
    const currentContext = this.getContext() || {};
    const newContext = { ...currentContext, correlationId };
    return this.runWithContext(newContext, fn);
  }

  // Express middleware for HTTP requests
  expressMiddleware() {
    return (req: any, res: any, next: any) => {
      const correlationId =
        (req.headers['x-correlation-id'] as string) || this.createCorrelationId();

      res.setHeader('x-correlation-id', correlationId);

      this.withCorrelation(correlationId, next);
    };
  }
}

export const correlationManager = new CorrelationManager();
```

### Workflow Logging Integration

```typescript
// packages/orchestrator/src/workflow-logger.ts
import { TammaLogger } from '@tamma/observability';
import { correlationManager } from '@tamma/observability';
import type { WorkflowContext, WorkflowStep } from './types';

export class WorkflowLogger {
  private logger: TammaLogger;

  constructor() {
    this.logger = new TammaLogger('orchestrator');
  }

  logWorkflowStart(context: WorkflowContext): void {
    this.logger.info('Workflow started', {
      correlationId: context.correlationId,
      workflowId: context.workflowId,
      issueId: context.issueId,
      userId: context.userId,
      step: 'WORKFLOW_START',
    });
  }

  logStepStart(step: WorkflowStep, context: WorkflowContext): void {
    this.logger.info(`Step started: ${step.name}`, {
      correlationId: context.correlationId,
      workflowId: context.workflowId,
      stepId: step.id,
      stepName: step.name,
      issueId: context.issueId,
      step: 'STEP_START',
    });
  }

  logStepComplete(step: WorkflowStep, context: WorkflowContext, duration: number): void {
    this.logger.info(`Step completed: ${step.name}`, {
      correlationId: context.correlationId,
      workflowId: context.workflowId,
      stepId: step.id,
      stepName: step.name,
      issueId: context.issueId,
      duration,
      step: 'STEP_COMPLETE',
    });
  }

  logStepError(step: WorkflowStep, context: WorkflowContext, error: Error): void {
    this.logger.error(`Step failed: ${step.name}`, error, {
      correlationId: context.correlationId,
      workflowId: context.workflowId,
      stepId: step.id,
      stepName: step.name,
      issueId: context.issueId,
      step: 'STEP_ERROR',
    });
  }

  logWorkflowComplete(context: WorkflowContext, totalDuration: number): void {
    this.logger.info('Workflow completed', {
      correlationId: context.correlationId,
      workflowId: context.workflowId,
      issueId: context.issueId,
      userId: context.userId,
      totalDuration,
      step: 'WORKFLOW_COMPLETE',
    });
  }

  logWorkflowError(context: WorkflowContext, error: Error): void {
    this.logger.error('Workflow failed', error, {
      correlationId: context.correlationId,
      workflowId: context.workflowId,
      issueId: context.issueId,
      userId: context.userId,
      step: 'WORKFLOW_ERROR',
    });
  }

  // Create child logger with workflow context
  createWorkflowLogger(context: WorkflowContext): TammaLogger {
    return this.logger.child({
      correlationId: context.correlationId,
      workflowId: context.workflowId,
      issueId: context.issueId,
      userId: context.userId,
    });
  }
}
```

### Provider Logging

```typescript
// packages/providers/src/provider-logger.ts
import { TammaLogger } from '@tamma/observability';
import type { AIProvider, MessageRequest, MessageChunk } from './types';

export class ProviderLogger {
  private logger: TammaLogger;

  constructor(providerName: string) {
    this.logger = new TammaLogger('provider').child({ provider: providerName });
  }

  logRequest(request: MessageRequest, correlationId: string): void {
    this.logger.info('AI provider request initiated', {
      correlationId,
      provider: this.logger.options.base?.provider,
      model: request.model,
      messageCount: request.messages.length,
      hasSystemPrompt: !!request.system,
      maxTokens: request.maxTokens,
      temperature: request.temperature,
      step: 'PROVIDER_REQUEST_START',
    });
  }

  logResponse(chunks: MessageChunk[], correlationId: string, duration: number): void {
    const totalTokens = chunks.reduce((sum, chunk) => sum + (chunk.tokens || 0), 0);

    this.logger.info('AI provider request completed', {
      correlationId,
      provider: this.logger.options.base?.provider,
      chunkCount: chunks.length,
      totalTokens,
      duration,
      tokensPerSecond: totalTokens / (duration / 1000),
      step: 'PROVIDER_REQUEST_COMPLETE',
    });
  }

  logError(error: Error, correlationId: string): void {
    this.logger.error('AI provider request failed', error, {
      correlationId,
      provider: this.logger.options.base?.provider,
      step: 'PROVIDER_REQUEST_ERROR',
    });
  }

  logRateLimit(resetTime: Date, correlationId: string): void {
    this.logger.warn('AI provider rate limit hit', {
      correlationId,
      provider: this.logger.options.base?.provider,
      resetTime: resetTime.toISOString(),
      step: 'PROVIDER_RATE_LIMIT',
    });
  }
}
```

### Platform Logging

```typescript
// packages/platforms/src/platform-logger.ts
import { TammaLogger } from '@tamma/observability';
import type { GitPlatform, PullRequest, Issue } from './types';

export class PlatformLogger {
  private logger: TammaLogger;

  constructor(platformName: string) {
    this.logger = new TammaLogger('platform').child({ platform: platformName });
  }

  logIssueCreated(issue: Issue, correlationId: string): void {
    this.logger.info('Issue created', {
      correlationId,
      platform: this.logger.options.base?.platform,
      issueId: issue.id,
      issueNumber: issue.number,
      title: issue.title,
      step: 'PLATFORM_ISSUE_CREATED',
    });
  }

  logPRCreated(pr: PullRequest, correlationId: string): void {
    this.logger.info('Pull request created', {
      correlationId,
      platform: this.logger.options.base?.platform,
      prId: pr.id,
      prNumber: pr.number,
      title: pr.title,
      baseBranch: pr.baseBranch,
      headBranch: pr.headBranch,
      step: 'PLATFORM_PR_CREATED',
    });
  }

  logPRMerged(pr: PullRequest, correlationId: string): void {
    this.logger.info('Pull request merged', {
      correlationId,
      platform: this.logger.options.base?.platform,
      prId: pr.id,
      prNumber: pr.number,
      mergeCommitSha: pr.mergeCommitSha,
      step: 'PLATFORM_PR_MERGED',
    });
  }

  logAPIError(endpoint: string, error: Error, correlationId: string): void {
    this.logger.error(`Git platform API error: ${endpoint}`, error, {
      correlationId,
      platform: this.logger.options.base?.platform,
      endpoint,
      step: 'PLATFORM_API_ERROR',
    });
  }

  logRateLimit(resetTime: Date, correlationId: string): void {
    this.logger.warn('Git platform rate limit hit', {
      correlationId,
      platform: this.logger.options.base?.platform,
      resetTime: resetTime.toISOString(),
      step: 'PLATFORM_RATE_LIMIT',
    });
  }
}
```

## Implementation Tasks

### 1. Logger Configuration

```typescript
// packages/observability/src/config.ts
export interface LoggerConfig {
  level: 'debug' | 'info' | 'warn' | 'error';
  destination: 'stdout' | 'file' | 'service';
  filePath?: string;
  serviceName: string;
  redactionRules: RedactionRule[];
  performance: {
    maxLogSize: number;
    bufferSize: number;
    flushInterval: number;
  };
}

interface RedactionRule {
  pattern: RegExp;
  replacement: string;
}

export const defaultConfig: LoggerConfig = {
  level: (process.env.LOG_LEVEL as any) || 'info',
  destination: (process.env.LOG_DESTINATION as any) || 'stdout',
  filePath: process.env.LOG_FILE_PATH,
  serviceName: process.env.SERVICE_NAME || 'tamma',
  redactionRules: [
    { pattern: /password["\s]*[:=]["\s]*[^"\\s]+/gi, replacement: 'password="[REDACTED]"' },
    { pattern: /token["\s]*[:=]["\s]*[^"\\s]+/gi, replacement: 'token="[REDACTED]"' },
    { pattern: /key["\s]*[:=]["\s]*[^"\\s]+/gi, replacement: 'key="[REDACTED]"' },
    { pattern: /secret["\s]*[:=]["\s]*[^"\\s]+/gi, replacement: 'secret="[REDACTED]"' },
    {
      pattern: /authorization["\s]*[:=]["\s]*[^"\\s]+/gi,
      replacement: 'authorization="[REDACTED]"',
    },
  ],
  performance: {
    maxLogSize: 1024 * 1024, // 1MB
    bufferSize: 1000,
    flushInterval: 1000, // 1 second
  },
};
```

### 2. Log Rotation

```typescript
// packages/observability/src/rotation.ts
import { createWriteStream, WriteStream } from 'fs';
import { join } from 'path';

export class LogRotation {
  private writeStream: WriteStream | null = null;
  private currentSize = 0;
  private maxFileSize: number;
  private maxFiles: number;
  private filePath: string;

  constructor(filePath: string, maxFileSize = 100 * 1024 * 1024, maxFiles = 10) {
    this.filePath = filePath;
    this.maxFileSize = maxFileSize;
    this.maxFiles = maxFiles;
    this.createWriteStream();
  }

  private createWriteStream(): void {
    this.writeStream = createWriteStream(this.filePath, { flags: 'a' });
    this.currentSize = 0;
  }

  write(data: string): void {
    if (!this.writeStream) return;

    const dataSize = Buffer.byteLength(data, 'utf8');

    if (this.currentSize + dataSize > this.maxFileSize) {
      this.rotate();
    }

    this.writeStream.write(data);
    this.currentSize += dataSize;
  }

  private rotate(): void {
    if (this.writeStream) {
      this.writeStream.end();
    }

    // Rotate existing files
    for (let i = this.maxFiles - 1; i > 0; i--) {
      const oldFile = `${this.filePath}.${i}`;
      const newFile = `${this.filePath}.${i + 1}`;

      if (i === this.maxFiles - 1) {
        // Delete the oldest file
        try {
          require('fs').unlinkSync(oldFile);
        } catch (error) {
          // File might not exist
        }
      } else {
        try {
          require('fs').renameSync(oldFile, newFile);
        } catch (error) {
          // File might not exist
        }
      }
    }

    // Move current file to .1
    try {
      require('fs').renameSync(this.filePath, `${this.filePath}.1`);
    } catch (error) {
      // File might not exist
    }

    this.createWriteStream();
  }

  end(): void {
    if (this.writeStream) {
      this.writeStream.end();
      this.writeStream = null;
    }
  }
}
```

### 3. Performance Monitoring

```typescript
// packages/observability/src/performance.ts
export class LoggingPerformance {
  private static metrics = {
    logCount: 0,
    totalTime: 0,
    maxTime: 0,
    minTime: Infinity,
  };

  static measureLog<T>(fn: () => T): T {
    const start = process.hrtime.bigint();
    const result = fn();
    const end = process.hrtime.bigint();

    const duration = Number(end - start) / 1000000; // Convert to milliseconds

    this.metrics.logCount++;
    this.metrics.totalTime += duration;
    this.metrics.maxTime = Math.max(this.metrics.maxTime, duration);
    this.metrics.minTime = Math.min(this.metrics.minTime, duration);

    return result;
  }

  static getMetrics() {
    return {
      ...this.metrics,
      averageTime: this.metrics.totalTime / this.metrics.logCount,
      logsPerSecond: this.metrics.logCount / (this.metrics.totalTime / 1000),
    };
  }

  static resetMetrics(): void {
    this.metrics = {
      logCount: 0,
      totalTime: 0,
      maxTime: 0,
      minTime: Infinity,
    };
  }
}
```

## Testing Strategy

### 1. Unit Tests

```typescript
// packages/observability/test/logger.test.ts
describe('TammaLogger', () => {
  let logger: TammaLogger;
  let mockWrite: jest.MockedFunction<(data: string) => void>;

  beforeEach(() => {
    mockWrite = jest.fn();
    logger = new TammaLogger('test-service', {
      write: mockWrite,
    });
  });

  test('logs structured data with correct format', () => {
    logger.info('Test message', { key: 'value' });

    expect(mockWrite).toHaveBeenCalledWith(expect.stringContaining('"level":"info"'));
    expect(mockWrite).toHaveBeenCalledWith(expect.stringContaining('"message":"Test message"'));
    expect(mockWrite).toHaveBeenCalledWith(expect.stringContaining('"key":"value"'));
  });

  test('redacts sensitive data', () => {
    logger.info('Login attempt', {
      username: 'user',
      password: 'secret123',
      apiKey: 'key123',
    });

    const logOutput = mockWrite.mock.calls[0][0];
    expect(logOutput).toContain('"password":"[REDACTED]"');
    expect(logOutput).toContain('"apiKey":"[REDACTED]"');
    expect(logOutput).not.toContain('secret123');
    expect(logOutput).not.toContain('key123');
  });

  test('creates child logger with inherited context', () => {
    const childLogger = logger.child({ issueId: '123' });

    childLogger.info('Child message');

    expect(mockWrite).toHaveBeenCalledWith(expect.stringContaining('"issueId":"123"'));
  });
});
```

### 2. Performance Tests

```typescript
// packages/observability/test/performance.test.ts
describe('Logging Performance', () => {
  test('log overhead is under 5ms', () => {
    const logger = new TammaLogger('test');
    const iterations = 1000;

    const start = process.hrtime.bigint();

    for (let i = 0; i < iterations; i++) {
      logger.info(`Test message ${i}`, { iteration: i });
    }

    const end = process.hrtime.bigint();
    const totalTime = Number(end - start) / 1000000; // Convert to ms
    const averageTime = totalTime / iterations;

    expect(averageTime).toBeLessThan(5); // Less than 5ms per log
  });

  test('concurrent logging is thread-safe', async () => {
    const logger = new TammaLogger('test');
    const promises = [];

    for (let i = 0; i < 100; i++) {
      promises.push(
        new Promise((resolve) => {
          setTimeout(() => {
            logger.info(`Concurrent message ${i}`);
            resolve(null);
          }, Math.random() * 10);
        })
      );
    }

    await Promise.all(promises);

    // Should not throw any errors
    expect(true).toBe(true);
  });
});
```

## Success Metrics

### Logging Quality

- [ ] 100% of log statements use structured format
- [ ] All sensitive data properly redacted
- [ ] Correlation IDs present in 95%+ of log entries
- [ ] Log levels appropriately assigned
- [ ] Performance overhead <5ms per log statement

### Operational Excellence

- [ ] Log rotation working correctly
- [ ] Log volume <10 statements per typical event
- [ ] Search and filtering capabilities functional
- [ ] Integration with log aggregation services
- [ ] Monitoring of logging system health

### Developer Experience

- [ ] Easy-to-use logger API
- [ ] Clear documentation and examples
- [ ] Type safety for log context
- [ ] Debug mode with verbose logging
- [ ] Performance metrics available

## Dependencies

### Core Dependencies

```json
{
  "pino": "^8.17.0",
  "pino-pretty": "^10.3.0",
  "pino-roll": "^4.0.0"
}
```

### Development Dependencies

```json
{
  "@types/pino": "^7.0.5",
  "pino-test": "^1.0.0"
}
```

## Risks and Mitigations

### Performance Impact

- **Risk**: Logging overhead affects application performance
- **Mitigation**: Async logging, buffering, performance monitoring

### Log Volume

- **Risk**: Excessive log volume overwhelms storage and processing
- **Mitigation**: Log level controls, sampling, intelligent filtering

### Data Leaks

- **Risk**: Sensitive data accidentally logged
- **Mitigation**: Comprehensive redaction rules, automated scanning

### Log Loss

- **Risk**: Log messages lost during high load
- **Mitigation**: Reliable transport, buffering, retry mechanisms

## Rollout Plan

### Phase 1: Core Implementation (Week 1)

1. Pino logger setup and configuration
2. Basic structured logging implementation
3. Correlation ID management

### Phase 2: Integration (Week 2)

1. Workflow logging integration
2. Provider and platform logging
3. Error handling and redaction

### Phase 3: Advanced Features (Week 3)

1. Log rotation and retention
2. Performance monitoring
3. Log aggregation integration

### Phase 4: Testing and Optimization (Week 4)

1. Comprehensive testing
2. Performance optimization
3. Documentation and training

## Completion Criteria

- [ ] Structured logging implemented across all services
- [ ] Correlation IDs flow through entire system
- [ ] Sensitive data redaction working correctly
- [ ] Log levels properly assigned and configurable
- [ ] Performance overhead under 5ms per log statement
- [ ] Log rotation and retention policies implemented
- [ ] Integration with log aggregation services tested
- [ ] Comprehensive test coverage (>90%)
- [ ] Documentation and examples provided
- [ ] Production deployment successful

---

**Story Context**: This story implements comprehensive structured logging across the Tamma platform using Pino, providing correlation ID tracking, sensitive data redaction, performance monitoring, and integration with log aggregation services to enable effective debugging and system observability.
