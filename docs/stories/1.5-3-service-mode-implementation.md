# Story 1.5-3: Service Mode Implementation

**Epic:** 1.5 - Deployment, Packaging & Operations  
**Status:** Ready for Development  
**Priority:** MVP Critical  
**Estimated Effort:** 6 days

## Overview

Implement background daemon mode that listens for task queue events and automatically triggers autonomous development workflows. Service mode enables Tamma to operate without user interaction, processing webhook events, handling task queues, and managing concurrent autonomous workflows with configurable auto-approval settings.

## Technical Context

### ‚ö†Ô∏è Development Process Reminder

**Before implementing this story, ensure you have:**
1. ‚úÖ Read [BEFORE_YOU_CODE.md](../../BEFORE_YOU_CODE.md)
2. ‚úÖ Searched `.dev/` directory for related spikes, bugs, findings, and decisions
3. ‚úÖ Reviewed relevant documentation in `docs/` directory
4. ‚úÖ Checked existing code patterns for similar functionality
5. ‚úÖ Planned TDD approach (Red-Green-Refactor cycle)


Service mode is critical for Tamma's self-maintenance capability. It provides the foundation for webhook-triggered automation (Story 1.5-6) and enables Tamma to autonomously respond to issue assignments and PR events. The service runs as a background daemon, polling a task queue for work items and executing autonomous workflows using the core engine from Story 1.5-1.

The implementation must handle graceful shutdown, concurrent task processing, retry logic with exponential backoff, and auto-approval for low-complexity issues based on configurable criteria.

## Acceptance Criteria

1. Service starts as background daemon and listens for task queue events
2. Graceful shutdown on SIGTERM/SIGINT (finishes in-progress tasks, max 30 seconds)
3. Task polling interval configurable (default 5 seconds)
4. Maximum concurrent tasks configurable (default 3)
5. Auto-approval for low-complexity issues (configurable)
6. Retry logic with exponential backoff (max 3 retries)
7. Health check endpoint responds within 100ms
8. Service mode runs without user interaction (no prompts)
9. Unit tests validate task processing logic
10. Integration tests validate service lifecycle (start, process tasks, shutdown)

## Implementation Details

### Service Package Structure

```
packages/
‚îú‚îÄ‚îÄ server/                  # @tamma/server - Service & Web launch wrapper
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service/         # Service mode implementation
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.ts   # Main service class
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task-processor.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task-queue.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ health-check.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ queue/           # Task queue implementations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory-queue.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ redis-queue.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sqs-queue.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ webhooks/        # Webhook handlers (for Story 1.5-6)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ github.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gitlab.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/             # REST API (for Story 1.5-4)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ web.ts           # Web server (for Story 1.5-4)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.ts       # Service mode entry point
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts         # Server entry points
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ queue/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ tsconfig.json
```

### Main Service Class

```typescript
// @tamma/server/src/service/service.ts
import { EventEmitter } from 'events';
import { createEngine, TammaEngine } from '@tamma/core';
import { ITaskQueue, Task, TaskStatus, TaskType } from '../queue';
import { createLogger, ILogger } from '@tamma/observability';
import { ServiceConfig, TammaConfig } from '@tamma/config';

export interface ServiceMetrics {
  startTime: Date;
  tasksProcessed: number;
  tasksCompleted: number;
  tasksFailed: number;
  averageProcessingTime: number;
  activeTasks: number;
  queueDepth: number;
}

export class TammaService extends EventEmitter {
  private engine: TammaEngine;
  private queue: ITaskQueue;
  private logger: ILogger;
  private config: ServiceConfig;
  private metrics: ServiceMetrics;
  private pollInterval: NodeJS.Timeout | null = null;
  private activeTasks = new Map<string, Promise<void>>();
  private isShuttingDown = false;
  private gracefulShutdownTimeout: NodeJS.Timeout | null = null;

  constructor(config: ServiceConfig) {
    super();
    this.config = config;
    this.logger = createLogger('service', config.logLevel);
    this.queue = this.createTaskQueue(config.queue);
    this.metrics = this.initializeMetrics();
  }

  async start(): Promise<void> {
    this.logger.info('Starting Tamma service...', {
      mode: 'service',
      config: {
        pollInterval: config.pollInterval,
        maxConcurrentTasks: config.maxConcurrentTasks,
        autoApprove: config.autoApprove,
      },
    });

    try {
      // Initialize core engine
      this.engine = await createEngine({
        mode: 'service',
        config: config.tamma,
        logger: this.logger,
      });
      await this.engine.initialize();

      // Connect to task queue
      await this.queue.connect();
      this.logger.info('Connected to task queue', { type: config.queue.type });

      // Start task polling
      this.startPolling();

      // Register signal handlers for graceful shutdown
      this.registerSignalHandlers();

      this.metrics.startTime = new Date();
      this.logger.info('Tamma service started successfully', {
        pid: process.pid,
        nodeVersion: process.version,
        platform: process.platform,
      });

      this.emit('started');
    } catch (error) {
      this.logger.error('Failed to start service', { error });
      throw error;
    }
  }

  async stop(): Promise<void> {
    if (this.isShuttingDown) {
      this.logger.warn('Service shutdown already in progress');
      return;
    }

    this.isShuttingDown = true;
    this.logger.info('Shutting down Tamma service...');

    try {
      // Stop polling for new tasks
      if (this.pollInterval) {
        clearInterval(this.pollInterval);
        this.pollInterval = null;
      }

      // Wait for active tasks to complete (with timeout)
      const gracefulShutdownTimeout = setTimeout(() => {
        this.logger.warn('Graceful shutdown timeout, forcing exit');
        process.exit(1);
      }, 30000); // 30 second timeout

      // Wait for all active tasks
      const activeTaskPromises = Array.from(this.activeTasks.values());
      if (activeTaskPromises.length > 0) {
        this.logger.info('Waiting for active tasks to complete', {
          count: activeTaskPromises.length,
        });
        await Promise.allSettled(activeTaskPromises);
      }

      clearTimeout(gracefulShutdownTimeout);

      // Disconnect from queue
      await this.queue.disconnect();

      // Dispose engine
      if (this.engine) {
        await this.engine.dispose();
      }

      this.logger.info('Tamma service stopped successfully');
      this.emit('stopped');
    } catch (error) {
      this.logger.error('Error during service shutdown', { error });
      throw error;
    }
  }

  private startPolling(): void {
    this.pollInterval = setInterval(async () => {
      if (this.isShuttingDown) return;

      try {
        await this.processPendingTasks();
      } catch (error) {
        this.logger.error('Error in task polling loop', { error });
      }
    }, this.config.pollInterval);

    this.logger.debug('Task polling started', { interval: this.config.pollInterval });
  }

  private async processPendingTasks(): Promise<void> {
    // Check if we're at maximum concurrent tasks
    if (this.activeTasks.size >= this.config.maxConcurrentTasks) {
      this.logger.debug('Maximum concurrent tasks reached, skipping poll');
      return;
    }

    // Get next task from queue
    const task = await this.queue.dequeue();
    if (!task) {
      return; // No tasks available
    }

    this.logger.info('Processing task', {
      taskId: task.id,
      type: task.type,
      priority: task.priority,
    });

    // Process task asynchronously
    const taskPromise = this.processTask(task);
    this.activeTasks.set(task.id, taskPromise);

    // Clean up completed task from active tasks
    taskPromise.finally(() => {
      this.activeTasks.delete(task.id);
    });
  }

  private async processTask(task: Task): Promise<void> {
    const startTime = Date.now();
    this.metrics.activeTasks++;

    try {
      this.logger.info('Executing task', { taskId: task.id, type: task.type });

      // Update task status to in-progress
      await this.queue.updateStatus(task.id, TaskStatus.IN_PROGRESS);

      // Execute task based on type
      const result = await this.executeTaskByType(task);

      // Mark task as completed
      await this.queue.complete(task.id, result);

      const processingTime = Date.now() - startTime;
      this.updateTaskMetrics(true, processingTime);

      this.logger.info('Task completed successfully', {
        taskId: task.id,
        processingTime,
        result,
      });

      this.emit('taskCompleted', { task, result, processingTime });
    } catch (error) {
      const processingTime = Date.now() - startTime;
      this.logger.error('Task failed', {
        taskId: task.id,
        error: error.message,
        processingTime,
      });

      // Mark task as failed
      await this.queue.fail(task.id, error.message);

      this.updateTaskMetrics(false, processingTime);

      // Retry logic with exponential backoff
      if (task.retries < this.config.maxRetries) {
        const retryDelay = Math.min(
          this.config.retryDelay * Math.pow(2, task.retries),
          this.config.maxRetryDelay
        );

        this.logger.info('Retrying task', {
          taskId: task.id,
          attempt: task.retries + 1,
          delay: retryDelay,
        });

        setTimeout(async () => {
          await this.queue.retry(task.id, task.retries + 1);
        }, retryDelay);
      } else {
        this.logger.error('Task exceeded maximum retries, escalating', {
          taskId: task.id,
          maxRetries: this.config.maxRetries,
        });

        await this.escalateTask(task, error);
      }

      this.emit('taskFailed', { task, error, processingTime });
    } finally {
      this.metrics.activeTasks--;
    }
  }

  private async executeTaskByType(task: Task): Promise<any> {
    switch (task.type) {
      case TaskType.ISSUE_ASSIGNED:
        return await this.handleIssueAssigned(task.payload);

      case TaskType.ISSUE_COMMENT:
        return await this.handleIssueComment(task.payload);

      case TaskType.PR_REVIEW_REQUESTED:
        return await this.handlePRReviewRequested(task.payload);

      case TaskType.PR_COMMENT:
        return await this.handlePRComment(task.payload);

      default:
        throw new Error(`Unknown task type: ${task.type}`);
    }
  }

  private async handleIssueAssigned(payload: IssueAssignedPayload): Promise<any> {
    this.logger.info('Handling issue assignment', {
      repository: payload.repository,
      issueNumber: payload.issue.number,
    });

    // Select the specific issue
    const issue = await this.engine.selectIssue({
      number: payload.issue.number,
    });

    if (!issue) {
      throw new Error(`Issue #${payload.issue.number} not found`);
    }

    // Analyze issue
    const analysis = await this.engine.analyzeIssue(issue);

    // Generate development plan
    const plan = await this.engine.generatePlan(analysis);

    // Auto-approval logic
    const shouldAutoApprove = this.shouldAutoApprove(analysis, plan);

    if (shouldAutoApprove) {
      this.logger.info('Auto-approving development plan', {
        issueNumber: issue.number,
        complexity: analysis.complexity,
        riskLevel: analysis.riskLevel,
      });

      // Execute plan automatically
      await this.engine.createBranch(plan);
      const changes = await this.engine.implementCode(plan);
      const testResults = await this.engine.runTests(changes);
      const pr = await this.engine.createPullRequest(changes);

      return {
        action: 'auto_approved',
        issueNumber: issue.number,
        pullRequest: pr.url,
        testResults,
      };
    } else {
      // Escalate for human approval
      await this.escalateForApproval(issue, plan);

      return {
        action: 'escalated_for_approval',
        issueNumber: issue.number,
        reason: 'complexity_threshold_exceeded',
      };
    }
  }

  private async handleIssueComment(payload: IssueCommentPayload): Promise<any> {
    this.logger.info('Handling issue comment', {
      repository: payload.repository,
      issueNumber: payload.issue.number,
      commentAuthor: payload.comment.author,
    });

    // Check if comment is a command for Tamma
    const comment = payload.comment.body.toLowerCase();

    if (comment.includes('@tamma') || comment.includes('/tamma')) {
      if (comment.includes('start') || comment.includes('work on this')) {
        // Trigger workflow for this issue
        return await this.handleIssueAssigned({
          repository: payload.repository,
          issue: payload.issue,
        });
      }
    }

    return { action: 'ignored', reason: 'not_a_command' };
  }

  private async handlePRReviewRequested(payload: PRReviewRequestedPayload): Promise<any> {
    this.logger.info('Handling PR review request', {
      repository: payload.repository,
      pullRequestNumber: payload.pullRequest.number,
    });

    // Monitor PR status and handle merge if appropriate
    const prStatus = await this.engine.monitorPR(payload.pullRequest);

    if (prStatus.mergeable && prStatus.ciPassed) {
      const mergeResult = await this.engine.mergePR(payload.pullRequest);

      return {
        action: 'merged',
        pullRequestNumber: payload.pullRequest.number,
        mergeResult,
      };
    }

    return {
      action: 'monitoring',
      pullRequestNumber: payload.pullRequest.number,
      status: prStatus,
    };
  }

  private async handlePRComment(payload: PRCommentPayload): Promise<any> {
    this.logger.info('Handling PR comment', {
      repository: payload.repository,
      pullRequestNumber: payload.pullRequest.number,
      commentAuthor: payload.comment.author,
    });

    // Handle PR comments (e.g., merge commands, fix requests)
    const comment = payload.comment.body.toLowerCase();

    if (comment.includes('merge') || comment.includes('lgtm')) {
      // Trigger PR merge if conditions are met
      return await this.handlePRReviewRequested({
        repository: payload.repository,
        pullRequest: payload.pullRequest,
      });
    }

    return { action: 'ignored', reason: 'not_a_command' };
  }

  private shouldAutoApprove(analysis: IssueAnalysis, plan: DevelopmentPlan): boolean {
    const config = this.config.autoApprove;

    // Check complexity threshold
    if (analysis.complexity === 'low' && !config.lowComplexity) {
      return false;
    }

    if (analysis.complexity === 'medium' && !config.mediumComplexity) {
      return false;
    }

    if (analysis.complexity === 'high' || analysis.complexity === 'critical') {
      return false; // Never auto-approve high complexity
    }

    // Check risk level
    if (analysis.riskLevel === 'high' || analysis.riskLevel === 'critical') {
      return false;
    }

    // Check estimated effort
    if (plan.estimatedHours > config.maxEstimatedHours) {
      return false;
    }

    // Check for risky file patterns
    const riskyPatterns = config.blockFilePatterns || [];
    const hasRiskyFiles = plan.files.some((file) =>
      riskyPatterns.some((pattern) => file.includes(pattern))
    );

    if (hasRiskyFiles) {
      return false;
    }

    return true;
  }

  private async escalateForApproval(issue: Issue, plan: DevelopmentPlan): Promise<void> {
    this.logger.info('Escalating issue for human approval', {
      issueNumber: issue.number,
      complexity: plan.complexity,
    });

    // Create escalation task or notification
    // This could integrate with Slack, email, or create a GitHub issue
    // Implementation depends on escalation preferences

    this.emit('escalationRequired', { issue, plan });
  }

  private async escalateTask(task: Task, error: Error): Promise<void> {
    this.logger.error('Escalating failed task', {
      taskId: task.id,
      error: error.message,
      retries: task.retries,
    });

    // Create escalation notification
    this.emit('taskEscalated', { task, error });
  }

  private createTaskQueue(queueConfig: QueueConfig): ITaskQueue {
    switch (queueConfig.type) {
      case 'memory':
        return new MemoryTaskQueue(queueConfig);
      case 'redis':
        return new RedisTaskQueue(queueConfig.redis);
      case 'sqs':
        return new SQSTaskQueue(queueConfig.sqs);
      default:
        throw new Error(`Unsupported queue type: ${queueConfig.type}`);
    }
  }

  private registerSignalHandlers(): void {
    const shutdown = async (signal: string) => {
      this.logger.info(`Received ${signal}, initiating graceful shutdown`);
      try {
        await this.stop();
        process.exit(0);
      } catch (error) {
        this.logger.error('Error during shutdown', { error });
        process.exit(1);
      }
    };

    process.on('SIGTERM', () => shutdown('SIGTERM'));
    process.on('SIGINT', () => shutdown('SIGINT'));
    process.on('SIGUSR2', () => shutdown('SIGUSR2')); // Nodemon restart
  }

  private initializeMetrics(): ServiceMetrics {
    return {
      startTime: new Date(),
      tasksProcessed: 0,
      tasksCompleted: 0,
      tasksFailed: 0,
      averageProcessingTime: 0,
      activeTasks: 0,
      queueDepth: 0,
    };
  }

  private updateTaskMetrics(success: boolean, processingTime: number): void {
    this.metrics.tasksProcessed++;

    if (success) {
      this.metrics.tasksCompleted++;
    } else {
      this.metrics.tasksFailed++;
    }

    // Update average processing time
    const totalTime =
      this.metrics.averageProcessingTime * (this.metrics.tasksProcessed - 1) + processingTime;
    this.metrics.averageProcessingTime = totalTime / this.metrics.tasksProcessed;
  }

  // Public API methods
  getMetrics(): ServiceMetrics {
    return {
      ...this.metrics,
      queueDepth: this.queue.getDepth(),
    };
  }

  async getHealthStatus(): Promise<HealthStatus> {
    try {
      const queueHealth = await this.queue.getHealthStatus();
      const engineHealth = this.engine ? 'healthy' : 'unhealthy';

      return {
        status: 'healthy',
        uptime: Date.now() - this.metrics.startTime.getTime(),
        metrics: this.getMetrics(),
        components: {
          queue: queueHealth,
          engine: engineHealth,
        },
      };
    } catch (error) {
      return {
        status: 'unhealthy',
        error: error.message,
        uptime: Date.now() - this.metrics.startTime.getTime(),
      };
    }
  }
}

// Service mode entry point
export async function startService(config: ServiceConfig): Promise<TammaService> {
  const service = new TammaService(config);
  await service.start();
  return service;
}
```

### Task Queue Interface

```typescript
// @tamma/server/src/queue/index.ts
export interface ITaskQueue {
  // Connection management
  connect(): Promise<void>;
  disconnect(): Promise<void>;
  getHealthStatus(): Promise<QueueHealthStatus>;

  // Task operations
  enqueue(task: TaskPayload): Promise<Task>;
  dequeue(): Promise<Task | null>;
  get(taskId: string): Promise<Task | null>;
  list(filters?: TaskFilters): Promise<Task[]>;

  // Status management
  updateStatus(taskId: string, status: TaskStatus): Promise<void>;
  complete(taskId: string, result?: any): Promise<void>;
  fail(taskId: string, error: string): Promise<void>;
  retry(taskId: string, retryCount: number): Promise<void>;
  cancel(taskId: string): Promise<void>;

  // Queue information
  getDepth(): number;
  getStats(): QueueStats;
}

export interface Task {
  id: string;
  type: TaskType;
  priority: TaskPriority;
  payload: any;
  status: TaskStatus;
  retries: number;
  maxRetries: number;
  createdAt: Date;
  startedAt?: Date;
  completedAt?: Date;
  error?: string;
  result?: any;
}

export enum TaskType {
  ISSUE_ASSIGNED = 'issue_assigned',
  ISSUE_COMMENT = 'issue_comment',
  PR_REVIEW_REQUESTED = 'pr_review_requested',
  PR_COMMENT = 'pr_comment',
}

export enum TaskPriority {
  LOW = 0,
  MEDIUM = 1,
  HIGH = 2,
  CRITICAL = 3,
}

export enum TaskStatus {
  QUEUED = 'queued',
  IN_PROGRESS = 'in_progress',
  COMPLETED = 'completed',
  FAILED = 'failed',
  CANCELLED = 'cancelled',
}

export interface TaskPayload {
  type: TaskType;
  priority: TaskPriority;
  payload: any;
  maxRetries?: number;
}

export interface TaskFilters {
  status?: TaskStatus;
  type?: TaskType;
  priority?: TaskPriority;
  limit?: number;
  offset?: number;
}

export interface QueueStats {
  total: number;
  queued: number;
  inProgress: number;
  completed: number;
  failed: number;
}

export interface QueueHealthStatus {
  status: 'healthy' | 'degraded' | 'unhealthy';
  message?: string;
  latency?: number;
  errorRate?: number;
}

export interface HealthStatus {
  status: 'healthy' | 'unhealthy';
  uptime: number;
  error?: string;
  metrics?: ServiceMetrics;
  components?: {
    queue: QueueHealthStatus;
    engine: string;
  };
}
```

### Memory Task Queue Implementation

```typescript
// @tamma/server/src/queue/memory-queue.ts
import {
  ITaskQueue,
  Task,
  TaskPayload,
  TaskStatus,
  TaskFilters,
  QueueStats,
  QueueHealthStatus,
} from './index';
import { randomUUID } from 'crypto';

export class MemoryTaskQueue implements ITaskQueue {
  private tasks = new Map<string, Task>();
  private isConnecting = false;
  private isConnected = false;

  constructor(private config: any) {}

  async connect(): Promise<void> {
    this.isConnecting = true;
    // Simulate connection delay
    await new Promise((resolve) => setTimeout(resolve, 100));
    this.isConnected = true;
    this.isConnecting = false;
  }

  async disconnect(): Promise<void> {
    this.isConnected = false;
    this.tasks.clear();
  }

  async getHealthStatus(): Promise<QueueHealthStatus> {
    return {
      status: this.isConnected ? 'healthy' : 'unhealthy',
      latency: 1, // Memory operations are ~1ms
    };
  }

  async enqueue(payload: TaskPayload): Promise<Task> {
    const task: Task = {
      id: randomUUID(),
      type: payload.type,
      priority: payload.priority,
      payload: payload.payload,
      status: TaskStatus.QUEUED,
      retries: 0,
      maxRetries: payload.maxRetries || 3,
      createdAt: new Date(),
    };

    this.tasks.set(task.id, task);
    return task;
  }

  async dequeue(): Promise<Task | null> {
    // Find highest priority queued task
    const queuedTasks = Array.from(this.tasks.values())
      .filter((task) => task.status === TaskStatus.QUEUED)
      .sort((a, b) => {
        // Sort by priority (high to low), then by creation time (oldest first)
        if (a.priority !== b.priority) {
          return b.priority - a.priority;
        }
        return a.createdAt.getTime() - b.createdAt.getTime();
      });

    if (queuedTasks.length === 0) {
      return null;
    }

    const task = queuedTasks[0];
    task.status = TaskStatus.IN_PROGRESS;
    task.startedAt = new Date();

    return task;
  }

  async get(taskId: string): Promise<Task | null> {
    return this.tasks.get(taskId) || null;
  }

  async list(filters: TaskFilters = {}): Promise<Task[]> {
    let tasks = Array.from(this.tasks.values());

    // Apply filters
    if (filters.status) {
      tasks = tasks.filter((task) => task.status === filters.status);
    }
    if (filters.type) {
      types = tasks.filter((task) => task.type === filters.type);
    }
    if (filters.priority) {
      tasks = tasks.filter((task) => task.priority === filters.priority);
    }

    // Sort by creation time (newest first)
    tasks.sort((a, b) => b.createdAt.getTime() - a.createdAt.getTime());

    // Apply pagination
    if (filters.offset) {
      tasks = tasks.slice(filters.offset);
    }
    if (filters.limit) {
      tasks = tasks.slice(0, filters.limit);
    }

    return tasks;
  }

  async updateStatus(taskId: string, status: TaskStatus): Promise<void> {
    const task = this.tasks.get(taskId);
    if (task) {
      task.status = status;
    }
  }

  async complete(taskId: string, result?: any): Promise<void> {
    const task = this.tasks.get(taskId);
    if (task) {
      task.status = TaskStatus.COMPLETED;
      task.completedAt = new Date();
      task.result = result;
    }
  }

  async fail(taskId: string, error: string): Promise<void> {
    const task = this.tasks.get(taskId);
    if (task) {
      task.status = TaskStatus.FAILED;
      task.error = error;
    }
  }

  async retry(taskId: string, retryCount: number): Promise<void> {
    const task = this.tasks.get(taskId);
    if (task) {
      task.status = TaskStatus.QUEUED;
      task.retries = retryCount;
      task.startedAt = undefined;
      task.error = undefined;
    }
  }

  async cancel(taskId: string): Promise<void> {
    const task = this.tasks.get(taskId);
    if (task) {
      task.status = TaskStatus.CANCELLED;
    }
  }

  getDepth(): number {
    return Array.from(this.tasks.values()).filter((task) => task.status === TaskStatus.QUEUED)
      .length;
  }

  getStats(): QueueStats {
    const tasks = Array.from(this.tasks.values());

    return {
      total: tasks.length,
      queued: tasks.filter((t) => t.status === TaskStatus.QUEUED).length,
      inProgress: tasks.filter((t) => t.status === TaskStatus.IN_PROGRESS).length,
      completed: tasks.filter((t) => t.status === TaskStatus.COMPLETED).length,
      failed: tasks.filter((t) => t.status === TaskStatus.FAILED).length,
    };
  }
}
```

### Service Mode Entry Point

```typescript
// @tamma/server/src/service.ts
import { startService, TammaService } from './service/service';
import { loadConfig } from '@tamma/config';
import { createLogger } from '@tamma/observability';

async function main(): Promise<void> {
  const logger = createLogger('main');

  try {
    // Load configuration
    const config = await loadConfig();

    if (config.mode !== 'service') {
      throw new Error('Invalid mode. Expected "service" mode.');
    }

    // Start service
    const service = await startService(config.service);

    // Handle service events
    service.on('started', () => {
      logger.info('Tamma service is running');
    });

    service.on('stopped', () => {
      logger.info('Tamma service has stopped');
    });

    service.on('taskCompleted', ({ task, result }) => {
      logger.info('Task completed', { taskId: task.id, result });
    });

    service.on('taskFailed', ({ task, error }) => {
      logger.error('Task failed', { taskId: task.id, error: error.message });
    });

    service.on('escalationRequired', ({ issue, plan }) => {
      logger.warn('Escalation required', {
        issueNumber: issue.number,
        complexity: plan.complexity,
      });
    });

    // Keep process alive
    process.on('SIGTERM', async () => {
      logger.info('Received SIGTERM, shutting down');
      await service.stop();
    });

    process.on('SIGINT', async () => {
      logger.info('Received SIGINT, shutting down');
      await service.stop();
    });
  } catch (error) {
    logger.error('Failed to start service', { error });
    process.exit(1);
  }
}

if (require.main === module) {
  main();
}
```

## Testing Strategy

### Unit Tests

```typescript
// @tamma/server/tests/service/service.test.ts
import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
import { TammaService } from '../../../src/service/service';
import { MemoryTaskQueue } from '../../../src/queue/memory-queue';
import { createEngine } from '@tamma/core';

vi.mock('@tamma/core');

describe('TammaService', () => {
  let service: TammaService;
  let mockEngine: any;
  let mockQueue: any;
  let config: any;

  beforeEach(() => {
    mockEngine = {
      initialize: vi.fn(),
      dispose: vi.fn(),
      selectIssue: vi.fn(),
      analyzeIssue: vi.fn(),
      generatePlan: vi.fn(),
      createBranch: vi.fn(),
      implementCode: vi.fn(),
      runTests: vi.fn(),
      createPullRequest: vi.fn(),
      monitorPR: vi.fn(),
      mergePR: vi.fn(),
    };

    mockQueue = new MemoryTaskQueue({});
    vi.spyOn(mockQueue, 'connect');
    vi.spyOn(mockQueue, 'disconnect');
    vi.spyOn(mockQueue, 'dequeue');
    vi.spyOn(mockQueue, 'complete');
    vi.spyOn(mockQueue, 'fail');

    vi.mocked(createEngine).mockResolvedValue(mockEngine);

    config = {
      pollInterval: 100,
      maxConcurrentTasks: 2,
      maxRetries: 3,
      retryDelay: 1000,
      maxRetryDelay: 10000,
      autoApprove: {
        lowComplexity: true,
        mediumComplexity: false,
        maxEstimatedHours: 4,
        blockFilePatterns: ['package.json', 'yarn.lock'],
      },
      queue: { type: 'memory' },
      tamma: {},
      logLevel: 'info',
    };

    service = new TammaService(config);
  });

  afterEach(async () => {
    if (service) {
      await service.stop();
    }
    vi.clearAllMocks();
  });

  describe('service lifecycle', () => {
    it('should start service and connect to queue', async () => {
      await service.start();

      expect(createEngine).toHaveBeenCalledWith({
        mode: 'service',
        config: config.tamma,
        logger: expect.any(Object),
      });

      expect(mockEngine.initialize).toHaveBeenCalled();
      expect(mockQueue.connect).toHaveBeenCalled();
    });

    it('should shutdown gracefully', async () => {
      await service.start();
      await service.stop();

      expect(mockQueue.disconnect).toHaveBeenCalled();
      expect(mockEngine.dispose).toHaveBeenCalled();
    });

    it('should handle SIGTERM gracefully', async () => {
      await service.start();

      // Simulate SIGTERM
      process.emit('SIGTERM', 'SIGTERM');

      // Wait for graceful shutdown
      await new Promise((resolve) => setTimeout(resolve, 100));

      expect(mockQueue.disconnect).toHaveBeenCalled();
    });
  });

  describe('task processing', () => {
    beforeEach(async () => {
      await service.start();
    });

    it('should process issue assigned task', async () => {
      const task = {
        id: 'test-task-1',
        type: 'issue_assigned',
        priority: 1,
        payload: {
          repository: 'test/repo',
          issue: { number: 123, title: 'Test Issue' },
        },
        status: 'queued',
        retries: 0,
        maxRetries: 3,
        createdAt: new Date(),
      };

      mockQueue.dequeue.mockResolvedValue(task);
      mockEngine.selectIssue.mockResolvedValue(task.payload.issue);
      mockEngine.analyzeIssue.mockResolvedValue({ complexity: 'low', riskLevel: 'low' });
      mockEngine.generatePlan.mockResolvedValue({
        complexity: 'low',
        estimatedHours: 2,
        files: ['src/test.ts'],
      });

      // Wait for task processing
      await new Promise((resolve) => setTimeout(resolve, 200));

      expect(mockEngine.selectIssue).toHaveBeenCalledWith({ number: 123 });
      expect(mockEngine.analyzeIssue).toHaveBeenCalled();
      expect(mockEngine.generatePlan).toHaveBeenCalled();
      expect(mockEngine.createBranch).toHaveBeenCalled();
      expect(mockEngine.implementCode).toHaveBeenCalled();
      expect(mockEngine.runTests).toHaveBeenCalled();
      expect(mockEngine.createPullRequest).toHaveBeenCalled();
      expect(mockQueue.complete).toHaveBeenCalledWith(task.id, expect.any(Object));
    });

    it('should retry failed tasks', async () => {
      const task = {
        id: 'test-task-2',
        type: 'issue_assigned',
        priority: 1,
        payload: {
          repository: 'test/repo',
          issue: { number: 456, title: 'Failing Issue' },
        },
        status: 'queued',
        retries: 0,
        maxRetries: 3,
        createdAt: new Date(),
      };

      mockQueue.dequeue.mockResolvedValue(task);
      mockEngine.selectIssue.mockRejectedValue(new Error('Test failure'));

      // Wait for task processing and retry
      await new Promise((resolve) => setTimeout(resolve, 300));

      expect(mockQueue.fail).toHaveBeenCalledWith(task.id, 'Test failure');
      expect(mockQueue.retry).toHaveBeenCalledWith(task.id, 1);
    });

    it('should respect concurrent task limits', async () => {
      const tasks = Array.from({ length: 5 }, (_, i) => ({
        id: `task-${i}`,
        type: 'issue_assigned',
        priority: 1,
        payload: { repository: 'test/repo', issue: { number: i } },
        status: 'queued',
        retries: 0,
        maxRetries: 3,
        createdAt: new Date(),
      }));

      mockQueue.dequeue
        .mockResolvedValueOnce(tasks[0])
        .mockResolvedValueOnce(tasks[1])
        .mockResolvedValueOnce(tasks[2])
        .mockResolvedValueOnce(tasks[3])
        .mockResolvedValueOnce(tasks[4]);

      // Make first two tasks take longer
      mockEngine.selectIssue.mockImplementation(async () => {
        await new Promise((resolve) => setTimeout(resolve, 200));
        return { number: 123, title: 'Test Issue' };
      });

      // Wait for processing
      await new Promise((resolve) => setTimeout(resolve, 100));

      // Should only process 2 tasks concurrently (maxConcurrentTasks = 2)
      expect(mockEngine.selectIssue).toHaveBeenCalledTimes(2);
    });
  });

  describe('auto-approval logic', () => {
    beforeEach(async () => {
      await service.start();
    });

    it('should auto-approve low complexity issues', async () => {
      const task = {
        id: 'test-task-3',
        type: 'issue_assigned',
        priority: 1,
        payload: {
          repository: 'test/repo',
          issue: { number: 789, title: 'Simple Issue' },
        },
        status: 'queued',
        retries: 0,
        maxRetries: 3,
        createdAt: new Date(),
      };

      mockQueue.dequeue.mockResolvedValue(task);
      mockEngine.selectIssue.mockResolvedValue(task.payload.issue);
      mockEngine.analyzeIssue.mockResolvedValue({
        complexity: 'low',
        riskLevel: 'low',
      });
      mockEngine.generatePlan.mockResolvedValue({
        complexity: 'low',
        estimatedHours: 2,
        files: ['src/simple.ts'],
      });

      await new Promise((resolve) => setTimeout(resolve, 200));

      expect(mockEngine.createBranch).toHaveBeenCalled();
      expect(mockEngine.implementCode).toHaveBeenCalled();
    });

    it('should not auto-approve high complexity issues', async () => {
      const task = {
        id: 'test-task-4',
        type: 'issue_assigned',
        priority: 1,
        payload: {
          repository: 'test/repo',
          issue: { number: 101, title: 'Complex Issue' },
        },
        status: 'queued',
        retries: 0,
        maxRetries: 3,
        createdAt: new Date(),
      };

      mockQueue.dequeue.mockResolvedValue(task);
      mockEngine.selectIssue.mockResolvedValue(task.payload.issue);
      mockEngine.analyzeIssue.mockResolvedValue({
        complexity: 'high',
        riskLevel: 'high',
      });
      mockEngine.generatePlan.mockResolvedValue({
        complexity: 'high',
        estimatedHours: 8,
        files: ['src/complex.ts'],
      });

      await new Promise((resolve) => setTimeout(resolve, 200));

      expect(mockEngine.createBranch).not.toHaveBeenCalled();
      expect(mockEngine.implementCode).not.toHaveBeenCalled();
    });
  });
});
```

### Integration Tests

```typescript
// @tamma/server/tests/integration/service-lifecycle.test.ts
import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import { TammaService } from '../../src/service/service';
import { loadConfig } from '@tamma/config';

describe('Service Integration Tests', () => {
  let service: TammaService;
  let config: any;

  beforeAll(async () => {
    // Load test configuration
    config = await loadConfig('./test-config.yaml');
    config.mode = 'service';
    config.service.pollInterval = 100; // Fast polling for tests
    config.service.maxConcurrentTasks = 1;
  });

  afterAll(async () => {
    if (service) {
      await service.stop();
    }
  });

  it('should start service and process tasks end-to-end', async () => {
    service = new TammaService(config.service);
    await service.start();

    // Verify service is healthy
    const health = await service.getHealthStatus();
    expect(health.status).toBe('healthy');

    // Verify metrics
    const metrics = service.getMetrics();
    expect(metrics.startTime).toBeInstanceOf(Date);
    expect(metrics.activeTasks).toBe(0);
  }, 10000);

  it('should handle graceful shutdown with active tasks', async () => {
    service = new TammaService(config.service);
    await service.start();

    // Simulate active task (this would normally come from queue)
    // For integration test, we just verify shutdown doesn't hang

    const shutdownStart = Date.now();
    await service.stop();
    const shutdownTime = Date.now() - shutdownStart;

    // Should shutdown quickly (no active tasks)
    expect(shutdownTime).toBeLessThan(1000);
  }, 5000);
});
```

## Configuration

### Service Configuration Schema

```typescript
// @tamma/config/src/schemas/service.schema.ts
export const ServiceConfigSchema = z.object({
  // Service mode settings
  pollInterval: z.number().min(100).max(60000).default(5000),
  maxConcurrentTasks: z.number().min(1).max(20).default(3),
  maxRetries: z.number().min(0).max(10).default(3),
  retryDelay: z.number().min(100).max(300000).default(5000),
  maxRetryDelay: z.number().min(1000).max(3600000).default(300000),

  // Auto-approval settings
  autoApprove: z
    .object({
      lowComplexity: z.boolean().default(true),
      mediumComplexity: z.boolean().default(false),
      maxEstimatedHours: z.number().min(1).max(40).default(8),
      blockFilePatterns: z
        .array(z.string())
        .default(['package.json', 'yarn.lock', 'package-lock.json', 'pnpm-lock.yaml']),
    })
    .default({}),

  // Queue configuration
  queue: z
    .object({
      type: z.enum(['memory', 'redis', 'sqs']).default('memory'),
      redis: z
        .object({
          url: z.string().url(),
          keyPrefix: z.string().default('tamma:'),
          maxRetriesPerRequest: z.number().default(3),
        })
        .optional(),
      sqs: z
        .object({
          queueUrl: z.string(),
          region: z.string(),
          accessKeyId: z.string().optional(),
          secretAccessKey: z.string().optional(),
        })
        .optional(),
    })
    .default({ type: 'memory' }),

  // Health check configuration
  healthCheck: z
    .object({
      enabled: z.boolean().default(true),
      port: z.number().min(1).max(65535).default(8080),
      path: z.string().default('/health'),
    })
    .default({}),

  // Metrics configuration
  metrics: z
    .object({
      enabled: z.boolean().default(true),
      port: z.number().min(1).max(65535).default(9090),
      path: z.string().default('/metrics'),
    })
    .default({}),
});

export type ServiceConfig = z.infer<typeof ServiceConfigSchema>;
```

## Performance Considerations

1. **Concurrent Task Processing**: Configurable concurrency limits prevent resource exhaustion
2. **Queue Polling**: Efficient polling with configurable intervals
3. **Memory Management**: Proper cleanup of completed tasks and engine instances
4. **Retry Logic**: Exponential backoff prevents overwhelming systems
5. **Graceful Shutdown**: Completes in-progress tasks before exit

## Security Considerations

1. **Task Validation**: Validate all task payloads before processing
2. **Resource Limits**: Enforce CPU and memory limits per task
3. **Error Information**: Avoid exposing sensitive information in error messages
4. **Access Control**: Ensure tasks only access authorized repositories
5. **Audit Trail**: Log all task processing for security auditing

## Monitoring and Observability

1. **Health Checks**: Comprehensive health status including queue and engine
2. **Metrics**: Task processing rates, success/failure rates, queue depth
3. **Structured Logging**: Detailed logs with task context and correlation IDs
4. **Event Emission**: Service events for external monitoring systems
5. **Performance Tracking**: Processing times and resource usage

## Dependencies

### Internal Dependencies

- `@tamma/core` - Core engine for workflow execution
- `@tamma/config` - Configuration management
- `@tamma/observability` - Logging and metrics

### External Dependencies

- `ioredis` - Redis client (for Redis queue)
- `@aws-sdk/client-sqs` - AWS SQS client (for SQS queue)

## Success Metrics

1. **Reliability**: >99% uptime, <5% task failure rate
2. **Performance**: <5 second task processing latency, <100ms health check response
3. **Scalability**: Support for 10+ concurrent tasks, 1000+ tasks/hour
4. **Recovery**: Graceful handling of failures, automatic retry with backoff
5. **Resource Efficiency**: <2GB memory usage, <50% CPU usage under load

---

## ‚ö†Ô∏è MANDATORY: Before You Code

**ALL contributors MUST read and follow the comprehensive development process:**

üìñ **[BEFORE_YOU_CODE.md](../../BEFORE_YOU_CODE.md)**

This mandatory guide includes:
- 7-Phase Development Workflow (Read ‚Üí Research ‚Üí Break Down ‚Üí TDD ‚Üí Quality Gates ‚Üí Failure Handling)
- Knowledge Base Usage (.dev/ directory: spikes, bugs, findings, decisions)
- TRACE/DEBUG Logging Requirements for all functions
- Test-Driven Development (TDD) mandatory workflow
- 100% Test Coverage requirement
- Build Success enforcement
- Automatic retry and developer alert procedures

**Failure to follow this process will result in rework.**

---

**Technical Context Created:** 2025-10-29  
**Last Updated:** 2025-10-29  
**Next Story:** 1.5-4 - Web Server & API

### References

- **üî¥ MANDATORY PROCESS:** [BEFORE_YOU_CODE.md](../../BEFORE_YOU_CODE.md)
- **Knowledge Base:** [.dev/README.md](../../.dev/README.md) - Search spikes, bugs, findings, decisions
